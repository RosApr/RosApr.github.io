
个人总结:

npm 

因为依赖提升的问题，会导致

- 幽灵依赖
- 相同子依赖的重复安装
- 顺序安装导致的可能的版本混乱 (npm install 后 node_modules结构可能不一致)

yarn

优点:
- 全局安装的模式可以让我们离线安装已经存在的依赖
- 并行下载的方式使得依赖安装更快
- lockfile声明直接依赖跟其子依赖的的关系，使得版本混乱问题得以解决，node_modules更加稳定



缺点
- 依然没有解决幽灵依赖的问题
- 还是存在依赖分身的问题

pnpm

不同于扁平化的node_modules跟依赖提升，pnpm采用内容寻址模式通过硬链接跟符号链接的形式来管理依赖，全局安装, 依托于node的模块加载机制

优点
- 因为全局安装使得本地已经有的依赖不用再次下载，直接通过软连接的形式链接
- node_modules 更加干净，避免了幽灵依赖的问题
- 不同版本的依赖有特殊的算法会尽量缓存相同文件，（解决依赖分身问题）

缺点
- 因为依靠符号链接的形式所以需要平台支持(Electron不支持)

        





## 首先他们都是包管理工具

> 使用场景
> 当我们的项目存在依赖第三方模块时，我们需要通过包管理工具来管理这些第三方依赖

### 嵌套的 node_modules 结构

npm 在早期采用的是嵌套的 node_modules 结构，直接依赖会平铺在 node_modules 下，子依赖嵌套在直接依赖的 node_modules 中。

比如项目依赖了 A 和 C，而 A 和 C 依赖了不同版本的 B@1.0 和 B@2.0，node_modules 结构如下：

```html
node_modules
├── A@1.0.0
│   └── node_modules
│       └── B@1.0.0
└── C@1.0.0
    └── node_modules
        └── B@2.0.0
```

如果 D 也依赖 B@1.0，会生成如下的嵌套结构：

```html
node_modules
├── A@1.0.0
│   └── node_modules
│       └── B@1.0.0
├── C@1.0.0
│   └── node_modules
│       └── B@2.0.0
└── D@1.0.0
    └── node_modules
        └── B@1.0.0
```

可以看到同版本的 B 分别被 A 和 D 安装了两次。

在真实场景下，依赖增多，冗余的包也变多，node_modules 最终会堪比黑洞，很快就能把磁盘占满。 而且依赖嵌套的深度也会十分可怕，这个就是依赖地狱。

### 依赖地狱 Dependency Hell

在真实场景下，依赖增多，冗余的包也变多，node_modules 最终会堪比黑洞，很快就能把磁盘占满。 而且依赖嵌套的深度也会十分可怕，这个就是依赖地狱。

### 扁平的 node_modules 结构

为了将嵌套的依赖尽量打平，避免过深的依赖树和包冗余，npm v3 将子依赖「提升」（hoist），采用**扁平的 node_modules 结构**，子依赖会尽量平铺安装在主依赖项所在的目录中。

```html
node_modules
├── A@1.0.0
├── B@1.0.0
└── C@1.0.0
    └── node_modules
        └── B@2.0.0
```

可以看到 A 的子依赖的 B@1.0 不再放在 A 的 node_modules 下了，而是与 A 同层级。

而 C 依赖的B@2.0因为版本号原因还是嵌套在 C 的 node_modules 下。

这样不会造成大量包的重复安装，依赖的层级也不会太深，解决了依赖地狱问题，但也形成了新的问题。

### 幽灵依赖 Phantom dependencies

幽灵依赖是指在 package.json 中未定义的依赖，但项目中依然可以正确地被引用到。

比如上方的示例其实我们只安装了 A 和 C：

```html
{
  "dependencies": {
    "A": "^1.0.0",
    "C": "^1.0.0"
  }
}
```

由于 B 在安装时被提升到了和 A 同样的层级，所以在项目中引用 B 还是能正常工作的。

幽灵依赖是由依赖的声明丢失造成的，如果某天某个版本的 A 依赖不再依赖 B 或者 B 的版本发生了变化，那么就会造成依赖缺失或兼容性问题。

### 不确定性 Non-Determinism

不确定性是指：同样的 package.json 文件，install 依赖后可能不会得到同样的 node_modules 目录结构。

还是之前的例子，A 依赖B@1.0，C 依赖B@2.0，依赖安装后究竟应该提升 B 的 1.0 还是 2.0。

```html
node_modules
├── A@1.0.0
├── B@1.0.0
└── C@1.0.0
    └── node_modules
        └── B@2.0.0
```

```html
node_modules
├── A@1.0.0
│   └── node_modules
│       └── B@1.0.0
├── B@2.0.0
└── C@1.0.0
```

取决于用户的安装顺序。

如果有 package.json 变更，本地需要删除 node_modules 重新 install，否则可能会导致生产环境与开发环境 node_modules 结构不同，代码无法正常运行。

### 依赖分身 Doppelgangers

假设继续再安装依赖 B@1.0 的 D 模块和依赖 @B2.0 的 E 模块，此时：

A 和 D 依赖 B@1.0

C 和 E 依赖 B@2.0

以下是提升 B@1.0 的 node_modules 结构：

```html
node_modules
├── A@1.0.0
├── B@1.0.0
├── D@1.0.0
├── C@1.0.0
│   └── node_modules
│       └── B@2.0.0
└── E@1.0.0
    └── node_modules
        └── B@2.0.0
```

可以看到B@2.0 会被安装两次，实际上无论提升 B@1.0 还是 B@2.0，都会存在重复版本的 B 被安装，这两个重复安装的 B 就叫 doppelgangers。

而且虽然看起来模块 C 和 E 都依赖 B@2.0，但其实引用的不是同一个 B，假设 B 在导出之前做了一些缓存或者副作用，那么用户的项目就会因此而出错。

以上是 npm 的问题

## yarn 的出现解决了一些 npm 带来的问题

2016 年，yarn 发布，yarn 也采用扁平化 node_modules 结构。 它的出现是为了解决 npm v3 几个最为迫在眉睫的问题：**依赖安装速度慢**，**不确定性**。

### 提升安装速度

在 npm 中安装依赖时，安装任务是串行的，会按包顺序逐个执行安装，这意味着它会等待一个包完全安装，然后再继续下一个。

为了加快包安装速度，yarn 采用了**并行操作**，在性能上有显著的提高。 而且在缓存机制上，yarn 会将每个包缓存在磁盘上，在下一次安装这个包时，可以脱离网络实现从磁盘离线安装。

### lockfile 解决不确定性

> yarn 更大的贡献是发明了 yarn.lock。

在依赖安装时，会根据 package.json 生成一份 yarn.lock 文件。

lockfile 里记录了依赖，以及依赖的子依赖，依赖的版本，获取地址与验证模块完整性的 hash。

即使是不同的安装顺序，相同的依赖关系在任何的环境和容器中，都能得到稳定的 node_modules 目录结构，保证了依赖安装的确定性。

所以 yarn 在出现时被定义为快速、安全、可靠的依赖管理。 而**npm 在一年后的 v5 才发布了 package-lock.json**。

### 与 npm 一样的弊端

yarn 依然和 npm 一样是扁平化的 node_modules 结构，没有解决幽灵依赖和依赖分身问题。

## pnpm

> pnpm - performant npm，在 2017 年正式发布，定义为快速的，节省磁盘空间的包管理工具，开创了一套新的依赖管理机制，成为了包管理的后起之秀。

### 内容寻址存储 CAS

与依赖提升和扁平化的 node_modules 不同，pnpm 引入了另一套依赖管理策略：**内容寻址存储**。

该策略会将包安装在系统的全局 store 中，依赖的每个版本只会在系统中安装一次。

在引用项目 node_modules 的依赖时，会通过**硬链接**与 **符号链接(软连接)** 在全局 store 中找到这个文件。 为了实现此过程，node_modules 下会多出 目录，而且是非扁平化结构。**.pnpm**

- **硬链接 Hard link**：硬链接可以理解为**源文件的副本**，项目里安装的其实是副本，它使得用户可以通过路径引用查找到全局 store 中的源文件，而且这个副本根本不占任何空间。 同时，pnpm 会在全局 store 里存储硬链接，不同的项目可以从全局 store 寻找到同一个依赖，大大地节省了磁盘空间。

- **符号链接** Symbolic link：也叫软连接，可以理解为**快捷方式**，pnpm 可以通过它找到对应磁盘目录下的依赖地址。

还是使用上面 A，B，C 模块的示例，使用 pnpm 安装依赖后 node_modules 结构如下：

```html
node_modules
├── .pnpm
│   ├── A@1.0.0
│   │   └── node_modules
│   │       ├── A => <store>/A@1.0.0
│   │       └── B => ../../B@1.0.0
│   ├── B@1.0.0
│   │   └── node_modules
│   │       └── B => <store>/B@1.0.0
│   ├── B@2.0.0
│   │   └── node_modules
│   │       └── B => <store>/B@2.0.0
│   └── C@1.0.0
│       └── node_modules
│           ├── C => <store>/C@1.0.0
│           └── B => ../../B@2.0.0
│
├── A => .pnpm/A@1.0.0/node_modules/A
└── C => .pnpm/C@1.0.0/node_modules/C
```

\<store\>xxx 开头的路径是硬链接，指向全局 store 中安装的依赖。

其余的是符号链接，指向依赖的快捷方式。

pnpm 官方图片也清晰地解释了这套机制：

![图片](./npm.png)

### 未来可期

这套全新的机制设计地十分巧妙，不仅兼容 node 的依赖解析，同时也解决了：

- 幽灵依赖问题：只有直接依赖会平铺在 node_modules 下，子依赖不会被提升，不会产生幽灵依赖。

- 依赖分身问题：相同的依赖只会在全局 store 中安装一次。 项目中的都是源文件的副本，几乎不占用任何空间，没有了依赖分身。

同时，由于链接的优势，pnpm 的安装速度在大多数场景都比 npm 和 yarn 快 2 倍，节省的磁盘空间也更多。

但也存在一些弊端：

- 由于 pnpm 创建的 node_modules 依赖软链接，因此在不支持软链接的环境中，无法使用 pnpm，比如 Electron 应用。

- 因为依赖源文件是安装在 store 中，调试依赖或 patch-package 给依赖打补丁也不太方便，可能会影响其他项目。

## yarn Plug'n'Play - 探索

2020 年 1 月，yarn v2 发布，也叫 yarn berry（v1 叫 yarn classic）。 它是对 yarn 的一次重大升级，其中一项重要更新就是 Plug'n'Play（Plug'n'Play = Plug and Play = PnP，即插即用）。

npm 与 yarn 的依赖安装与依赖解析都涉及大量的文件 I/O，效率不高。 开发 Plug'n'Play 最直接的原因就是依赖引用慢，依赖安装慢。

### 抛弃 node_modules

无论是 npm 还是 yarn，都具备缓存的功能，大多数情况下安装依赖时，其实是将缓存中的相关包复制到项目目录中 node_modules 里。

而 yarn PnP 则不会进行拷贝这一步，而是在项目里维护一张静态映射表 pnp.cjs。

pnp.cjs 会记录依赖在缓存中的具体位置，所有依赖都存在全局缓存中。 同时自建了一个解析器，在依赖引用时，帮助 node 从全局缓存目录中发现依赖，而不是查找 node_modules。

这样就避免了大量的 I/O 操作同时项目目录也不会有 node_modules 目录生成，同版本的依赖在全局也只会有一份，依赖的安装速度和解析速度都有较大提升。

pnpm 在 2020 年底的 v5.9 也支持了 PnP。

### 脱离 node 生态

pnp 比较明显的缺点是脱离了 node 生态。

因为使用 PnP 不会再有 node_modules 了，但是 Webpack，Babel 等各种前端工具都依赖 node_modules。 虽然很多工具比如 pnp-webpack-plugin 已经在解决了，但难免会有兼容性风险。

PnP 自建了依赖解析器，所有的依赖引用都必须由解析器执行，因此只能通过 yarn 命令来执行 node 脚本。

## 总结

目前还没有完美的依赖管理方案，可以看到在依赖管理的发展过程中，出现了：

不同的 node_modules 结构，有嵌套，扁平，甚至没有 node_modules，不同的结构也伴随着兼容与安全问题。

不同的依赖存储方式来节约磁盘空间，提升安装速度。

每种管理器都伴随新的工具和命令，不同程度的可配置性和扩展性，影响开发者体验。

这些包管理器也对 monorepo 有不同程度的支持，会直接影响项目的可维护性和速度。

库与开发者能够在这样优化与创新的发展过程中互相学习，站在巨人的肩膀上继续前进，不断推动前端工程领域的发展。

[参考](https://www.readfog.com/a/1673072431709917184)
